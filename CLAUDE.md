# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

mylhd is a Python package for collecting and analyzing data from the Large Helical Device (LHD) plasma physics experiment. The package provides tools for data retrieval from LABCOM systems and specialized analysis utilities.

## Architecture

### Package Structure
- `anadata.py`: Core module for LHD kaiseki data format parsing and retrieval from open data servers
- `labcom_retrieve/`: Package for retrieving measurement data from LABCOM systems via Retrieve.exe
- `cts_utls/`: CTS (Collective Thomson Scattering) analysis tools and utilities
- `test_claude/`: Directory for all testing files, test scripts, and test results

### Key Components

#### anadata.py
- `KaisekiData` class: Parses LHD kaiseki data format with multi-dimensional arrays
- Supports both local data server (`retrieve()`) and open data server (`retrieve_opendata()`) access
- Uses `igetfile` command for local server communication
- Data structure: dimensions + values with metadata (shot number, diagnostic names, units)
- Base URL: `https://exp.lhd.nifs.ac.jp/opendata/LHD/webapi.fcgi`

#### labcom_retrieve Package
- `LHDRetriever` class: Main interface for Windows/WSL-based data retrieval using Retrieve.exe
- `LHDData` dataclass: Container for measurement data with time axis, metadata, and voltage conversion
- WSL compatibility layer in `wsl_utils.py` for Linux environments accessing Windows executables
- Automatic cleanup of temporary files generated by Retrieve.exe
- Multiple channel retrieval with shared time axis optimization

#### cts_utls
- `CTSfosc_viewer.py`: CTS oscilloscope data analysis with STFT processing
- Spectrogram generation with marginal plots
- Real-time data processing with segment averaging and pixel reduction for performance

## Environment Requirements

### Windows/WSL Environment
The `labcom_retrieve` package requires Windows or WSL environment to access Retrieve.exe:
- Default paths checked: `/mnt/c/LABCOM/Retrieve/bin/Retrieve.exe`, `/mnt/c/LHD/Retrieve/Retrieve.exe`
- Working directory automatically set to Retrieve.exe parent directory
- Timeout: 5 minutes per retrieval operation

### Python Dependencies
- Core: `numpy`, `pandas`, `matplotlib`
- Signal processing: `scipy` (for STFT, FFT operations)
- Web requests: `urllib3` (for open data API)
- Data handling: Standard library modules (`os`, `subprocess`, `tempfile`)

## Common Usage Patterns

### Data Retrieval Examples
```python
# Kaiseki data from open server
data = KaisekiData.retrieve_opendata('diag_name', shot_no=123456, subno=1)

# LABCOM data retrieval
retriever = labcom_retrieve.LHDRetriever()
lhd_data = retriever.retrieve_data('Mag', shot=139400, subshot=1, channel=32, time_axis=True)

# Multiple channels
multi_data = retriever.retrieve_multiple_channels('Mag', 139400, 1, [1,2,3,4])
```

### Data Processing
- Raw data to voltage: Use `LHDData.val` or `LHDData.voltage` properties (applies VResolution and VOffset)
- Kaiseki data access: `get_dim_data(id)`, `get_val_data(id)` methods with dimension/variable names or indices
- CTS analysis: `save_plot()` function with shot number, diagnostic, and channel parameters

## File Naming Conventions
- Temporary files: `retrieve_{diag}_{shot}_{subshot}_{channel}.*`
- Output plots: `CTSfosc_{shot_num}.png`
- Data files from Retrieve.exe: `.dat` (binary data), `.prm` (parameters CSV), `.time` (time axis)

## Testing Guidelines

### Test Directory Structure
All testing-related files should be created in the `test_claude/` directory:
- Test scripts: Python files for testing package functionality
- Test data: Sample data files for testing
- Test results: Output files, plots, and analysis results from tests
- Temporary files: Any temporary files generated during testing

### Testing Best Practices
- Use the `test_claude/` directory for all testing activities
- Create descriptive test file names with clear purpose
- Clean up temporary files after testing when possible
- Document test procedures and expected outcomes

## Error Handling
- Automatic retry logic for data server timeouts
- Graceful degradation when optional files (.time, .prm) are missing
- WSL path validation and Windows executable compatibility checks
- Memory-efficient processing for large datasets (> 10M points)